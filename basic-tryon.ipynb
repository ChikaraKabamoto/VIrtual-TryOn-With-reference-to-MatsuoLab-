{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "条件付き対応追実験_.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ih36iA4J3V9"
      },
      "source": [
        "#GPUの種類を表示"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIR0Vn9GqsZf"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AeStj8zUKRyc"
      },
      "source": [
        "#Driveのマウント"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MW5Ml1sK7vSz"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bzlH7aLJ_u_"
      },
      "source": [
        "#ライブラリインポート"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8u6nfEF4wbFa"
      },
      "source": [
        "from __future__ import print_function\n",
        "#%matplotlib inline\n",
        "import argparse\n",
        "import os\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from IPython.display import HTML\n",
        "import time\n",
        "import subprocess as sp\n",
        "from datetime import datetime, timedelta, timezone\n",
        "import math\n",
        "from torchvision import datasets, models, transforms\n",
        "vgg19 = models.vgg19(pretrained=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHmOIscKKaOl"
      },
      "source": [
        "#GPUの使用時間を表示"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXBR7iM7acgp"
      },
      "source": [
        "res = sp.Popen([\"cat\", \"/proc/uptime\"], stdout=sp.PIPE)\n",
        "    # 単位はHour\n",
        "use_time = float(sp.check_output([\"awk\", \"{print $1 /60 /60 }\"], stdin=res.stdout).decode().replace(\"\\n\",\"\"))\n",
        "print(use_time)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8PHBB0fKmnE"
      },
      "source": [
        "#パラメータの定義"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIgiFDzawcXn"
      },
      "source": [
        "%cd drive/My\\ Drive\n",
        "dataroot1=\"new_persons\"\n",
        "dataroot2=\"new_cloths\"\n",
        "dataroot3=\"new_segmentations\"\n",
        "num_thread=0\n",
        "batch_size=16\n",
        "num_epoch=15\n",
        "img_size=(128,96)\n",
        "lr=0.0002\n",
        "b1=0.5\n",
        "b2=0.999\n",
        "ngpu=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w98OFtCBK9Ag"
      },
      "source": [
        "#データセットのロード"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBJQdqNZx1bp"
      },
      "source": [
        "p_dataset=dset.ImageFolder(root=dataroot1,\n",
        "                           transform=transforms.Compose([transforms.Resize(img_size),transforms.ToTensor(),]))\n",
        "c_dataset=dset.ImageFolder(root=dataroot2,\n",
        "                           transform=transforms.Compose([transforms.Resize(img_size),transforms.ToTensor(),]))\n",
        "seg_dataset=dset.ImageFolder(root=dataroot3,\n",
        "                           transform=transforms.Compose([transforms.Resize(img_size),transforms.ToTensor(),]))\n",
        "\n",
        "p_dataloader=torch.utils.data.DataLoader(p_dataset,batch_size=batch_size,shuffle=False,num_workers=num_thread)\n",
        "c_dataloader=torch.utils.data.DataLoader(c_dataset,batch_size=batch_size,shuffle=False,num_workers=num_thread)\n",
        "shuffle_c_dataloader=torch.utils.data.DataLoader(c_dataset,batch_size=batch_size,shuffle=True,num_workers=num_thread)\n",
        "seg_dataloader=torch.utils.data.DataLoader(seg_dataset,batch_size=batch_size,shuffle=False,num_workers=num_thread)      \n",
        "device=torch.device(\"cuda:0\")  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ej_dLxC7LUXP"
      },
      "source": [
        "#各種関数定義"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llSDEkKRLYbl"
      },
      "source": [
        "##衣服マスクの1チャネル化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYQdnvf8K4Wf"
      },
      "source": [
        "def onechanel_trans(x):\n",
        "    y=torch.zeros(1,x.size(0),1,128,96)\n",
        "    for k in range(x.size(0)):\n",
        "        for i in range(128):\n",
        "          for j in range(96):\n",
        "            G=x[k][1][i][j].item()\n",
        "            if (x[k][0][i][j]==1)and(round(G,4)==0.3333)and(x[k][2][i][j]==0):\n",
        "              y[0][k][0][i][j]=1\n",
        "    return y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujHsz1szLgZT"
      },
      "source": [
        "##マスクを人物画像にαブレンド"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2F60ePHK5K_"
      },
      "source": [
        "def overlay(x,y):\n",
        "    for k in range(x.size(0)):\n",
        "        for i in range(128):\n",
        "          for j in range(96):\n",
        "            if x[k][0][i][j]:\n",
        "              #y[k][0][i][j]=1\n",
        "              #y[k][1][i][j]=1\n",
        "              #y[k][2][i][j]=1\n",
        "              y[k,:,i,j]=1\n",
        "    return y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOIGlOy0Lx6O"
      },
      "source": [
        "##重みの初期化関数"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPPUGNSf436s"
      },
      "source": [
        "def init_weights(model):\n",
        "  if isinstance(model.modules,nn.Conv2d):\n",
        "      model.modules().weight.data.nomal_(0,0.002)\n",
        "      model.modules().bias.data.zero_()\n",
        "  if isinstance(model.modules,nn.ConvTranspose2d):\n",
        "      model.modules().weight.data.nomal_(0,0.002)\n",
        "      model.modules().bias.data.zero_()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naDZqxAtL0RS"
      },
      "source": [
        "#各種クラス定義"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhHT3w9fL8C0"
      },
      "source": [
        "##Encoder-Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdW4b4mY54Yj"
      },
      "source": [
        "class EncoderDecoder(nn.Module):\n",
        "  def __init__(self,ngpu):\n",
        "    super(EncoderDecoder,self).__init__()\n",
        "    self.ngpu=ngpu\n",
        "    #Encoder1\n",
        "    self.down1_1=nn.Conv2d(4,64,2,2,0,bias=False)\n",
        "    self.Leaky=nn.LeakyReLU(0.2,inplace=True)\n",
        "    self.down1_2=nn.Conv2d(64,128,2,2,0,bias=False)\n",
        "    self.batch1_1=nn.BatchNorm2d(128)\n",
        "    self.down1_3=nn.Conv2d(128,256,2,2,0,bias=False)\n",
        "    self.batch1_2=nn.BatchNorm2d(256)\n",
        "    self.down1_4=nn.Conv2d(256,512,2,2,0,bias=False)\n",
        "    self.batch1_3=nn.BatchNorm2d(512)\n",
        "    self.down1_5=nn.Conv2d(512,1024,2,2,0,bias=False)\n",
        "    self.batch1_4=nn.BatchNorm2d(1024)\n",
        "\n",
        "    #Encoder2\n",
        "    self.down2_1=nn.Conv2d(3,64,2,2,0,bias=False)\n",
        "    self.down2_2=nn.Conv2d(64,128,2,2,0,bias=False)\n",
        "    self.batch2_1=nn.BatchNorm2d(128)\n",
        "    self.down2_3=nn.Conv2d(128,256,2,2,0,bias=False)\n",
        "    self.batch2_2=nn.BatchNorm2d(256)\n",
        "    self.down2_4=nn.Conv2d(256,512,2,2,0,bias=False)\n",
        "    self.batch2_3=nn.BatchNorm2d(512)\n",
        "    self.down2_5=nn.Conv2d(512,1024,2,2,0,bias=False)\n",
        "    self.batch2_4=nn.BatchNorm2d(1024)\n",
        "\n",
        "    #Decoder\n",
        "    self.up3_1=nn.ConvTranspose2d(2048,1024,2,2,0,bias=False)\n",
        "    self.batch3_1=nn.BatchNorm2d(1024)\n",
        "    self.relu=nn.ReLU(True)\n",
        "    self.up3_2=nn.ConvTranspose2d(2048,512,2,2,0,bias=False)\n",
        "    self.batch3_2=nn.BatchNorm2d(512)\n",
        "    self.up3_3=nn.ConvTranspose2d(1024,256,2,2,0,bias=False)\n",
        "    self.batch3_3=nn.BatchNorm2d(256)\n",
        "    self.up3_4=nn.ConvTranspose2d(512,128,2,2,0,bias=False)\n",
        "    self.batch3_4=nn.BatchNorm2d(128)\n",
        "    self.up3_5=nn.ConvTranspose2d(256,64,2,2,0,bias=False)\n",
        "    self.batch3_5=nn.BatchNorm2d(64)\n",
        "    self.down3_1=\tnn.Conv2d(64,3,1,1,0,bias=False)\n",
        "    self.Sigmoid=nn.Sigmoid()\n",
        "\n",
        "  def Encoder1(self,input1): \n",
        "    down1_1=self.down1_1(input1)\n",
        "    self.Leaky1_1=self.Leaky(down1_1)\n",
        "    down1_2=self.down1_2(self.Leaky1_1)\n",
        "    batch1_1=self.batch1_1(down1_2)\n",
        "    self.Leaky1_2=self.Leaky(batch1_1)\n",
        "    down1_3=self.down1_3(self.Leaky1_2)\n",
        "    batch1_2=self.batch1_2(down1_3)\n",
        "    self.Leaky1_3=self.Leaky(batch1_2)\n",
        "    down1_4=self.down1_4(self.Leaky1_3)\n",
        "    batch1_3=self.batch1_3(down1_4)\n",
        "    self.Leaky1_4=self.Leaky(batch1_3)\n",
        "    down1_5=self.down1_5(self.Leaky1_4)\n",
        "    batch1_4=self.batch1_4(down1_5)\n",
        "    self.out1=self.Leaky(batch1_4)\n",
        "    return self.out1\n",
        "\n",
        "  def Encoder2(self,input2):\n",
        "    down2_1=self.down2_1(input2)\n",
        "    self.Leaky2_1=self.Leaky(down2_1)\n",
        "    down2_2=self.down2_2(self.Leaky2_1)\n",
        "    batch2_1=self.batch2_1(down2_2)\n",
        "    self.Leaky2_2=self.Leaky(batch2_1)\n",
        "    down2_3=self.down2_3(self.Leaky2_2)\n",
        "    batch2_2=self.batch2_2(down2_3)\n",
        "    self.Leaky2_3=self.Leaky(batch2_2)\n",
        "    down2_4=self.down2_4(self.Leaky2_3)\n",
        "    batch2_3=self.batch2_3(down2_4)\n",
        "    self.Leaky2_4=self.Leaky(batch2_3)\n",
        "    down2_5=self.down2_5(self.Leaky2_4)\n",
        "    batch2_4=self.batch2_4(down2_5)\n",
        "    self.out2=self.Leaky(batch2_4)\n",
        "    return self.out2\n",
        "  \n",
        "  def Decoder(self):\n",
        "    #print(self.out1.size(),self.out2.size())\n",
        "    Concatenate1=torch.cat([self.out1,self.out2],dim=1)\n",
        "    up3_1=self.up3_1(Concatenate1)\n",
        "    batch3_1=self.batch3_1(up3_1)\n",
        "    relu3_1=self.relu(batch3_1)\n",
        "    Concatenate2=torch.cat([relu3_1,self.Leaky1_4,self.Leaky2_4],dim=1)\n",
        "    up3_2=self.up3_2(Concatenate2)\n",
        "    batch3_2=self.batch3_2(up3_2)\n",
        "    relu3_2=self.relu(batch3_2)\n",
        "    Concatenate3=torch.cat([relu3_2,self.Leaky1_3,self.Leaky2_3],dim=1)\n",
        "    up3_3=self.up3_3(Concatenate3)\n",
        "    batch3_3=self.batch3_3(up3_3)\n",
        "    relu3_3=self.relu(batch3_3)\n",
        "    Concatenate4=torch.cat([relu3_3,self.Leaky1_2,self.Leaky2_2],dim=1)\n",
        "    up3_4=self.up3_4(Concatenate4)\n",
        "    batch3_4=self.batch3_4(up3_4)\n",
        "    relu3_4=self.relu(batch3_4)\n",
        "    Concatenate5=torch.cat([relu3_4,self.Leaky1_1,self.Leaky2_1],dim=1)\n",
        "    up3_5=self.up3_5(Concatenate5)\n",
        "    batch3_5=self.batch3_5(up3_5)\n",
        "    relu3_5=self.relu(batch3_5)\n",
        "    down3_1=self.down3_1(relu3_5)\n",
        "    out3=self.Sigmoid(down3_1)\n",
        "    #print(out3)\n",
        "    return out3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WT0VbY57MBn_"
      },
      "source": [
        "##Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GbUTb2oksos"
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "  def __init__(self,ngpu):\n",
        "    super(Discriminator,self).__init__()\n",
        "    self.ngpu=ngpu\n",
        "    self.down1=nn.Conv2d(6,64,2,2,0,bias=False)\n",
        "    self.Leaky=nn.LeakyReLU(0.2,inplace=True)\n",
        "    self.down2=nn.Conv2d(64,128,2,2,0,bias=False)\n",
        "    self.batch1=nn.BatchNorm2d(128)\n",
        "    self.down3=nn.Conv2d(128,256,2,2,0,bias=False)\n",
        "    self.batch2=nn.BatchNorm2d(256)\n",
        "    self.down4=nn.Conv2d(256,512,2,2,0,bias=False)\n",
        "    self.batch3=nn.BatchNorm2d(512)\n",
        "    self.down5=nn.Conv2d(512,1024,2,2,0,bias=False)\n",
        "    self.lastdown=nn.Conv2d(1024,1,(4,3),1,0,bias=False)\n",
        "    self.sigmoid=nn.Sigmoid()\n",
        "  \n",
        "  def Discriminator(self,input1,input2):\n",
        "    \n",
        "    input=torch.cat([input1,input2],dim=1)\n",
        "    #print(input1.size())\n",
        "    #print(input2.size())\n",
        "    down1=self.down1(input) \n",
        "    Leaky1=self.Leaky(down1)\n",
        "    down2=self.down2(Leaky1)\n",
        "    batch1=self.batch1(down2)\n",
        "    Leaky2=self.Leaky(batch1)\n",
        "    down3=self.down3(Leaky2)\n",
        "    batch2=self.batch2(down3)\n",
        "    Leaky3=self.Leaky(batch2)\n",
        "    down4=self.down4(Leaky3)\n",
        "    batch3=self.batch3(down4)\n",
        "    Leaky4=self.Leaky(batch3)\n",
        "    down5=self.down5(Leaky4)\n",
        "    lastdown=self.lastdown(down5)\n",
        "    #print(lastdown)\n",
        "    \n",
        "    out=self.sigmoid(lastdown)\n",
        "    #print(out)\n",
        "    return out\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwJpTEMxMF5g"
      },
      "source": [
        "##知覚損失"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58IEjbGT0GHq"
      },
      "source": [
        "class Vgg19Loss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Vgg19Loss, self).__init__()\n",
        "        features1=list(vgg19.features)[:3]\n",
        "        features2=list(vgg19.features)[:8]\n",
        "        features3=list(vgg19.features)[:13]\n",
        "        features4=list(vgg19.features)[:22]\n",
        "        features5=list(vgg19.features)[:31]\n",
        "        self.features1=nn.ModuleList(features1).eval()\n",
        "        self.features2=nn.ModuleList(features2).eval()\n",
        "        self.features3=nn.ModuleList(features3).eval()\n",
        "        self.features4=nn.ModuleList(features4).eval()\n",
        "        self.features5=nn.ModuleList(features5).eval()\n",
        "\n",
        "    def forward(self,x,y):\n",
        "        t1=x\n",
        "        t2=y\n",
        "        loss1=nn.MSELoss()\n",
        "        loss2=nn.MSELoss()\n",
        "        loss3=nn.MSELoss()\n",
        "        loss4=nn.MSELoss()\n",
        "        loss5=nn.MSELoss()\n",
        "\n",
        "        for f in self.features1:\n",
        "            x=f(x)\n",
        "            y=f(y)\n",
        "        #print(x,y)\n",
        "        f1loss=torch.sqrt(loss1(x,y)*64*128*96)\n",
        "    \n",
        "        \n",
        "        x=t1\n",
        "        y=t2\n",
        "        for f in self.features2:\n",
        "            x=f(x)\n",
        "            y=f(y)\n",
        "       # print(x.size(),y.size())\n",
        "        f2loss=torch.sqrt(loss2(x,y)*128*64*48)\n",
        "\n",
        "        x=t1\n",
        "        y=t2\n",
        "        for f in self.features3:\n",
        "            x=f(x)\n",
        "            y=f(y)\n",
        "       # print(x.size(),y.size())\n",
        "        f3loss=torch.sqrt(loss3(x,y)*256*32*24)\n",
        "\n",
        "        x=t1\n",
        "        y=t2\n",
        "        for f in self.features4:\n",
        "            x=f(x)\n",
        "            y=f(y)\n",
        "        #print(x.size(),y.size())\n",
        "        f4loss=torch.sqrt(loss4(x,y)*512*16*12)\n",
        "\n",
        "        x=t1\n",
        "        y=t2\n",
        "        for f in self.features5:\n",
        "            x=f(x)\n",
        "            y=f(y)\n",
        "        #print(x.size(),y.size())\n",
        "        f5loss=torch.sqrt(loss5(x,y)*512*8*6)\n",
        "\n",
        "        return f1loss+f2loss+f3loss+f4loss+f5loss\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNl3iJITMScH"
      },
      "source": [
        "#Unet(Encoder-Decoder)とDiscriminatorの初期化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsWE1tdLZQdQ"
      },
      "source": [
        "Unet=EncoderDecoder(ngpu).to(device)\n",
        "Unet.apply(init_weights)\n",
        "\n",
        "Discriminator=Discriminator(ngpu).to(device)\n",
        "Discriminator.apply(init_weights)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jH8UIvFMbzs"
      },
      "source": [
        "#損失関数&Adam最適化の定義"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CY88MHUI8lL"
      },
      "source": [
        "Ladv=nn.BCELoss()\n",
        "L1=nn.L1Loss()\n",
        "Lper=Vgg19Loss().to(device)\n",
        "\n",
        "real_label=1\n",
        "fake_label=0\n",
        "\n",
        "optimizerUnet=optim.Adam(Unet.parameters(),lr=lr,betas=(b1,b2))\n",
        "optimizerDiscriminator=optim.Adam(Discriminator.parameters(),lr=lr,betas=(b1,b2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pi8yeOy2Mv1Q"
      },
      "source": [
        "#学習"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hv2Ov9XSR4xB"
      },
      "source": [
        "img_list = []\n",
        "Unet_losses = []\n",
        "Generator_losses=[]\n",
        "Discriminator_losses = []\n",
        "iters = 0\n",
        "bepoch=0\n",
        "print(\"Starting Training Loop...\")\n",
        "start=time.time()\n",
        "for epoch in range(num_epoch):\n",
        "   epoch=epoch+bepoch\n",
        "   print(epoch)\n",
        "   iter_p = iter(p_dataloader)\n",
        "   iter_sub_p=iter(p_dataloader)\n",
        "   iter_c = iter(c_dataloader)\n",
        "   iter_shuffle_c=iter(shuffle_c_dataloader)\n",
        "   iter_seg=iter(seg_dataloader)\n",
        "   t1=time.time()\n",
        "   i=0\n",
        "   for p_data in p_dataloader:\n",
        "       #0.バッチデータの取得\n",
        "        p_real_batch=next(iter_p)\n",
        "        sub_p_real_batch=next(iter_sub_p)\n",
        "        c_real_batch=next(iter_c)\n",
        "        c_shuffle_real_batch=next(iter_shuffle_c)\n",
        "        seg_real_batch=next(iter_seg)\n",
        "       \n",
        "        p_b=p_real_batch[0].to(device)              #[][][][]\n",
        "        sub_p_b=sub_p_real_batch[0].to(device)      #[][][][]\n",
        "        c_t=c_real_batch[0].to(device)  \n",
        "        c_shuffle=c_shuffle_real_batch[0].to(device)            #[][][][]\n",
        "        seg_real_batch=seg_real_batch[0].to(device) #[][][][]\n",
        "\n",
        "\n",
        "        #1.衣服のマスクを作成\n",
        "        c_m=onechanel_trans(seg_real_batch).to(device)         #[][][][][]\n",
        "\n",
        "        #2.衣服のマスクと人物画像を重ね合わせる\n",
        "        p_m=overlay(c_m[0],sub_p_b).to(device)                 #[][][][]\n",
        "        \n",
        "        #3.Unetに衣服マスクと衣服を除いた人物画像、衣服画像を入力\n",
        "        Unet.Encoder1(torch.cat([p_m,c_m[0]],dim=1))\n",
        "        Unet.Encoder2(c_t)\n",
        "        p_a=Unet.Decoder().to(device)\n",
        "\n",
        "\n",
        "\n",
        "        #4.Discriminatorの学習\n",
        "        Discriminator.zero_grad()\n",
        "        b_size = p_b.size(0)#バッチサイズを計算\n",
        "\n",
        "        label = torch.full((b_size,), fill_value=real_label,dtype=torch.float32,device=device)#正解ラベルを設定\n",
        "        output = Discriminator.Discriminator(p_b,c_t).view(-1)#Discriminatorの出力を計算\n",
        "        Ladv_realD= Ladv(output, label)#損失を計算\n",
        "        Ladv_realD.backward()#勾配を計算\n",
        "        D_x = output.mean().item()\n",
        "\n",
        "        label.fill_(fake_label)#偽物ラベルを設定\n",
        "        output = Discriminator.Discriminator(p_a.detach(),c_t).view(-1) #Discriminatorの出力を計算\n",
        "        Ladv_fakeD1= Ladv(output, label)#損失を計算\n",
        "        Ladv_fakeD1.backward()#勾配を計算\n",
        "        D_G_z1 = output.mean().item()\n",
        "\n",
        "        output = Discriminator.Discriminator(p_b,c_shuffle).view(-1) #Discriminatorの出力を計算\n",
        "        Ladv_fakeD2= Ladv(output, label)#損失を計算\n",
        "        Ladv_fakeD2.backward()#勾配を計算\n",
        "        D_G_z2 = output.mean().item()\n",
        "        errD = Ladv_realD+ Ladv_fakeD1+Ladv_fakeD2#Tureの勾配とFalseの勾配を足す\n",
        "        optimizerDiscriminator.step() #discriminatorを更新\n",
        "\n",
        "\n",
        "\n",
        "        #5.Unetの学習\n",
        "        Unet.zero_grad() \n",
        "        label.fill_(real_label)#正解ラベルを設定\n",
        "        output = Discriminator.Discriminator(p_a,c_t).view(-1)#generatorが生成した画像を入力\n",
        "        Ladv_fakeG = Ladv(output, label)#損失を計算    \n",
        "        L1_fakeG=L1(p_a,p_b)#損失を計算\n",
        "        Lper_fakeG=Lper.forward(p_a,p_b)#損失を計算\n",
        "        L_G=Ladv_fakeG + L1_fakeG+Lper_fakeG#損失の合算\n",
        "        L_G.backward()#勾配を計算\n",
        "        D_G_z2 = output.mean().item()\n",
        "        optimizerUnet.step()  #Unetを更新\n",
        "\n",
        "\n",
        "\n",
        "        #6.損失を記録\n",
        "        Unet_losses.append(L_G.item())\n",
        "        Generator_losses.append(Ladv_fakeG.item())\n",
        "        Discriminator_losses.append(errD.item())\n",
        "\n",
        "        if (i%15==0):\n",
        "          \n",
        "            img_list.append(vutils.make_grid(p_a.detach(), padding=2, normalize=True))\n",
        "\n",
        "        i+=1\n",
        "        print(i)\n",
        "   print(epoch)\n",
        "   t2=time.time()\n",
        "   print(t2-t1)\n",
        "end=time.time()\n",
        "print(end-start)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3xFyrm6GWoL"
      },
      "source": [
        "#テスト1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJ9p9sVtNDMG"
      },
      "source": [
        "##テストデータのロード"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odVstx6qbpr_"
      },
      "source": [
        "test_dataroot1=\"test_persons\"\n",
        "test_dataroot2=\"test_cloths\"\n",
        "test_dataroot3=\"test_segmentations\"\n",
        "\n",
        "test_p_dataset=dset.ImageFolder(root=test_dataroot1,\n",
        "                           transform=transforms.Compose([transforms.Resize(img_size),transforms.ToTensor(),]))\n",
        "test_c_dataset=dset.ImageFolder(root=test_dataroot2,\n",
        "                           transform=transforms.Compose([transforms.Resize(img_size),transforms.ToTensor(),]))\n",
        "test_seg_dataset=dset.ImageFolder(root=test_dataroot3,\n",
        "                           transform=transforms.Compose([transforms.Resize(img_size),transforms.ToTensor(),]))\n",
        "\n",
        "test_p_dataloader=torch.utils.data.DataLoader(test_p_dataset,batch_size=64,shuffle=False,num_workers=num_thread)\n",
        "test_c_dataloader=torch.utils.data.DataLoader(test_c_dataset,batch_size=64,shuffle=False,num_workers=num_thread)\n",
        "test_seg_dataloader=torch.utils.data.DataLoader(test_seg_dataset,batch_size=64,shuffle=False,num_workers=num_thread)      \n",
        "device=torch.device(\"cuda:0\")  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kibQmxd9NRkn"
      },
      "source": [
        "##テスト実行"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJVKWFoigc8q"
      },
      "source": [
        "test_iter_p = iter(test_p_dataloader)\n",
        "test_iter_c = iter(test_c_dataloader)\n",
        "test_iter_seg=iter(test_seg_dataloader)\n",
        "for test_p_data in test_p_dataloader:\n",
        "     #バッチデータの取得\n",
        "     test_p_real_batch=next(test_iter_p)\n",
        "     test_c_real_batch=next(test_iter_c)\n",
        "     test_seg_real_batch=next(test_iter_seg)\n",
        "       \n",
        "     test_p_b=test_p_real_batch[0].to(device)              #[][][][]\n",
        "     test_c_t=test_c_real_batch[0].to(device)              #[][][][]\n",
        "     test_seg_real_batch=test_seg_real_batch[0].to(device) #[][][][]\n",
        "\n",
        "     #1.衣服のセグメンテーションマップを作成\n",
        "     test_c_m=onechanel_trans(test_seg_real_batch).to(device)         #[][][][][]\n",
        "\n",
        "     #2.衣服のセグメンテーションマップと人物画像を重ね合わせる\n",
        "     test_p_m=overlay(test_c_m[0],test_p_b).to(device)                 #[][][][]\n",
        "        \n",
        "     #3.Unetに衣服マスクと衣服を除いた人物画像、衣服画像を入力\n",
        "     Unet.Encoder1(torch.cat([test_p_m,test_c_m[0]],dim=1))\n",
        "     Unet.Encoder2(test_c_t)\n",
        "     test_p_a=Unet.Decoder().to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JevvnQ7vNaco"
      },
      "source": [
        "##生成画像を表示"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZiZB4Up_iC0q"
      },
      "source": [
        "image_num=64\n",
        "plt.imshow(np.transpose(vutils.make_grid(test_p_a.detach().to(device)[:image_num], padding=2, normalize=True).cpu(),(1,2,0)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NnkMx8TaKKj"
      },
      "source": [
        "#テスト2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phTzUBUXaa-x"
      },
      "source": [
        "##テストデータのロード\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMzoBtY_aQRY"
      },
      "source": [
        "test_dataroot1=\"good_persons_s\"\n",
        "test_dataroot2=\"good_cloths_s\"\n",
        "test_dataroot3=\"good_segmentations_s\"\n",
        "\n",
        "test_p_dataset=dset.ImageFolder(root=test_dataroot1,\n",
        "                           transform=transforms.Compose([transforms.Resize(img_size),transforms.ToTensor(),]))\n",
        "test_c_dataset=dset.ImageFolder(root=test_dataroot2,\n",
        "                           transform=transforms.Compose([transforms.Resize(img_size),transforms.ToTensor(),]))\n",
        "test_seg_dataset=dset.ImageFolder(root=test_dataroot3,\n",
        "                           transform=transforms.Compose([transforms.Resize(img_size),transforms.ToTensor(),]))\n",
        "\n",
        "test_p_dataloader=torch.utils.data.DataLoader(test_p_dataset,batch_size=1,shuffle=False,num_workers=num_thread)\n",
        "test_c_dataloader=torch.utils.data.DataLoader(test_c_dataset,batch_size=10,shuffle=False,num_workers=num_thread)\n",
        "test_seg_dataloader=torch.utils.data.DataLoader(test_seg_dataset,batch_size=1,shuffle=False,num_workers=num_thread)      \n",
        "device=torch.device(\"cuda:0\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRnaml3safxb"
      },
      "source": [
        "##テスト実行"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RcL_VXKaRwx"
      },
      "source": [
        "stop=10\n",
        "i=0\n",
        "test_p_a=[]\n",
        "test_iter_p = iter(test_p_dataloader)\n",
        "test_iter_c = iter(test_c_dataloader)\n",
        "test_iter_seg=iter(test_seg_dataloader)\n",
        "test_c_real_batch=next(test_iter_c)\n",
        "for test_p_data in test_p_dataloader:\n",
        "        #バッチデータの取得\n",
        "     test_p_real_batch=next(test_iter_p)\n",
        "     test_seg_real_batch=next(test_iter_seg)\n",
        "\n",
        "     m2=torch.cat([test_p_real_batch[0],test_p_real_batch[0]],dim=0)\n",
        "     m4=torch.cat([m2,m2],dim=0)\n",
        "     m8=torch.cat([m4,m4],dim=0)\n",
        "     m10=torch.cat([m8,m2],dim=0)\n",
        "\n",
        "     s2=torch.cat([test_seg_real_batch[0],test_seg_real_batch[0]],dim=0)\n",
        "     s4=torch.cat([s2,s2],dim=0)\n",
        "     s8=torch.cat([s4,s4],dim=0)\n",
        "     s10=torch.cat([s8,s2],dim=0)\n",
        "\n",
        "     test_p_b=m10.to(device)              #[][][][]\n",
        "     test_c_t=test_c_real_batch[0].to(device)              #[][][][]\n",
        "     test_seg_real_batch=s10.to(device) #[][][][]\n",
        "\n",
        "     #1.衣服のセグメンテーションマップを作成\n",
        "     test_c_m=onechanel_trans(test_seg_real_batch).to(device)         #[][][][][]\n",
        "\n",
        "     #2.衣服のセグメンテーションマップと人物画像を重ね合わせる\n",
        "     test_p_m=overlay(test_c_m[0],test_p_b).to(device)                 #[][][][]\n",
        "        \n",
        "     #3.Unetに衣服マスクと衣服を除いた人物画像、衣服画像を入力\n",
        "     Unet.Encoder1(torch.cat([test_p_m,test_c_m[0]],dim=1))\n",
        "     Unet.Encoder2(test_c_t)\n",
        "     temp=Unet.Decoder().to(device)\n",
        "     \n",
        "     if i==0:\n",
        "       test_p_a=temp\n",
        "     else:\n",
        "       test_p_a=torch.cat([test_p_a,temp],dim=0)\n",
        "    \n",
        "     if i==stop:\n",
        "       break\n",
        "     i+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2mxiqIRak2C"
      },
      "source": [
        "##生成画像を表示"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTYQEfUfaUHR"
      },
      "source": [
        "image_num=64\n",
        "plt.imshow(np.transpose(vutils.make_grid(test_p_a[:13].detach(), padding=2, normalize=True).cpu(),(1,2,0)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcEvZShQNwXi"
      },
      "source": [
        "#モデルの退避"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZWHLFwMvUI5"
      },
      "source": [
        "def avoid_Unet():    \n",
        "    PATHUnet='drive/My Drive/models/Unet_6_5242_17_advloss.pth'\n",
        "    torch.save({\n",
        "            'epoch': epoch,\n",
        "            'image':img_list,\n",
        "            'Unet_losses':Unet_losses,\n",
        "            'Generator':Generator_losses,\n",
        "            'model_state_dict': Unet.state_dict(),\n",
        "            'optimizer_state_dict': optimizerUnet.state_dict(),\n",
        "            'criterion1':Ladv.state_dict(),\n",
        "            'criterion2':L1.state_dict(),\n",
        "            'criterion3':Lper.state_dict()\n",
        "\n",
        "            }, PATHUnet)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFzMeZOlvcmF"
      },
      "source": [
        "def avoid_D():\n",
        "    PATHD='drive/My Drive/models/Discriminator_6_5242_17_advloss.pth'\n",
        "    torch.save({\n",
        "            'Disciriminator_losses':Discriminator_losses,\n",
        "            'model_state_dict': Discriminator.state_dict(),\n",
        "            'optimizer_state_dict': optimizerDiscriminator.state_dict()\n",
        "            }, PATHD)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_qJd8PgzNou"
      },
      "source": [
        "avoid_Unet()\n",
        "avoid_D()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1AnWocYN4kl"
      },
      "source": [
        "#モデルのロード"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5ihSBzJWJzo"
      },
      "source": [
        "%cd drive/My\\ Drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BY10IdqOzXma"
      },
      "source": [
        "%cd .."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cSWvS6LfJtQ"
      },
      "source": [
        "PATHG='drive/My Drive/models/Unet_2.7_5242_16.5_advloss.pth'\n",
        "#Unet = EncoderDecoder(ngpu).to(device)\n",
        "optimizerUnet= optim.Adam(Unet.parameters(),lr=lr,betas=(b1,b2))\n",
        "Ladv=nn.BCELoss()\n",
        "L1=nn.L1Loss()\n",
        "Lper=Vgg19Loss().to(device)\n",
        "\n",
        "checkpoint = torch.load(PATHG)\n",
        "Unet.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizerUnet.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "Ladv.load_state_dict(checkpoint['criterion1'])\n",
        "L1.load_state_dict(checkpoint['criterion2'])\n",
        "Lper.load_state_dict(checkpoint['criterion3'])\n",
        "bepoch = checkpoint['epoch']\n",
        "img_list=checkpoint['image']\n",
        "Unet_losses=checkpoint['Unet_losses']\n",
        "Generator_losses=checkpoint['Generator']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqF1XwzFh-P5"
      },
      "source": [
        "PATHD='drive/My Drive/models/Discriminator_2.7_5242_16.5_advloss.pth'\n",
        "#Discriminator=Discriminator(ngpu).to(device)\n",
        "optimizerDiscriminator=optim.Adam(Discriminator.parameters(),lr=lr,betas=(b1,b2))\n",
        "\n",
        "checkpoint = torch.load(PATHD)\n",
        "Discriminator.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizerDiscriminator.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "Discriminator_losses=checkpoint['Disciriminator_losses']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55VqfgLjN_EX"
      },
      "source": [
        "#損失の表示"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmTlkLoKti6U"
      },
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.title(\"Generator and Discriminator Loss During Training\")\n",
        "plt.plot(Generator_losses,label=\"G\")\n",
        "plt.plot( Discriminator_losses,label=\"D\")\n",
        "plt.xlabel(\"iterations\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIz-xBjKuvlt"
      },
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.title(\"Unet Loss During Training\")\n",
        "plt.plot(Unet_losses,label=\"Unet\")\n",
        "#plt.plot( Discriminator_losses,label=\"D\")\n",
        "plt.xlabel(\"iterations\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}